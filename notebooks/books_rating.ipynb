{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Entendimento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sucesso!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1882931173</td>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
       "      <td>4.0</td>\n",
       "      <td>940636800</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>Kevin Killian</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1095724800</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>John Granger</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1078790400</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>Roy E. Perry \"amateur philosopher\"</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1090713600</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                           Title  Price         User_id  \\\n",
       "0  1882931173  Its Only Art If Its Well Hung!    NaN   AVCGYZL8FQQTD   \n",
       "1  0826414346        Dr. Seuss: American Icon    NaN  A30TK6U7DNS82R   \n",
       "2  0826414346        Dr. Seuss: American Icon    NaN  A3UH4UZ4RSVO82   \n",
       "3  0826414346        Dr. Seuss: American Icon    NaN  A2MVUWT453QH61   \n",
       "\n",
       "                          profileName  score        time  \\\n",
       "0               Jim of Oz \"jim-of-oz\"    4.0   940636800   \n",
       "1                       Kevin Killian    5.0  1095724800   \n",
       "2                        John Granger    5.0  1078790400   \n",
       "3  Roy E. Perry \"amateur philosopher\"    4.0  1090713600   \n",
       "\n",
       "                                           summary  \\\n",
       "0           Nice collection of Julie Strain images   \n",
       "1                                Really Enjoyed It   \n",
       "2  Essential for every personal and Public Library   \n",
       "3  Phlip Nel gives silly Seuss a serious treatment   \n",
       "\n",
       "                                                text  \n",
       "0  This is only for Julie Strain fans. It's a col...  \n",
       "1  I don't care much for Dr. Seuss but after read...  \n",
       "2  If people become the books they read and if \"t...  \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent.parent \n",
    "DATA_DIR = PROJECT_ROOT / \"case_a3data\" # pasta raiz\n",
    "\n",
    "try:\n",
    "    csv_path = DATA_DIR / \"books_rating.csv\"\n",
    "    df_begin = pd.read_csv(csv_path)\n",
    "    print(f\"✅ Sucesso!\")\n",
    "    display(df_begin.head(4))\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Erro: Arquivo não encontrado em:\\n{csv_path}\")\n",
    "    print(\"Verifique a estrutura de pastas:\")\n",
    "    print(f\"Diretório atual: {Path.cwd()}\")\n",
    "    print(f\"Raiz do projeto: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000000 entries, 0 to 2999999\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count    Dtype  \n",
      "---  ------       --------------    -----  \n",
      " 0   Id           3000000 non-null  object \n",
      " 1   Title        2999792 non-null  object \n",
      " 2   Price        481171 non-null   float64\n",
      " 3   User_id      2438213 non-null  object \n",
      " 4   profileName  2438095 non-null  object \n",
      " 5   score        3000000 non-null  float64\n",
      " 6   time         3000000 non-null  int64  \n",
      " 7   summary      2999593 non-null  object \n",
      " 8   text         2999992 non-null  object \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 206.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_begin.info(show_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                   0\n",
      "Title              208\n",
      "Price          2518829\n",
      "User_id         561787\n",
      "profileName     561905\n",
      "score                0\n",
      "time                 0\n",
      "summary            407\n",
      "text                 8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_begin.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Limpeza dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Excluir linhas onde não há título do livro\n",
    "* Excluir User_id e profileName onde há registros vazios\n",
    "* converter data (UNIX PARA DATA)\n",
    "* tratar os nulos\n",
    "* Pode haver múltiplas avaliações para o mesmo livro-usuário. VERIFICAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratado = df_begin.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisando colunas 'Title', 'User_id' e 'profileName'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208 valores nulos em Title\n",
      "561787 valores nulos em User_id\n",
      "561905 valores nulos em profileName\n"
     ]
    }
   ],
   "source": [
    "# Contagem de valores nulos em 'Title', 'User_id' e 'profileName'\n",
    "print(f'{df_tratado[\"Title\"].isnull().sum()} valores nulos em Title')\n",
    "print(f'{df_tratado[\"User_id\"].isnull().sum()} valores nulos em User_id')\n",
    "print(f'{df_tratado[\"profileName\"].isnull().sum()} valores nulos em profileName')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluir linhas onde o título está vazio\n",
    "df_tratado = df_tratado[df_tratado['Title'].notna()]\n",
    "\n",
    "# Excluir User_id e profileName onde há registros vazios\n",
    "# Exclui porque haverá análises de usuários com opiniões relevantes. Em um primeiro momento, vou excluir os nulos.\n",
    "df_tratado = df_tratado[df_tratado['User_id'].notna()]\n",
    "df_tratado = df_tratado[df_tratado['profileName'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converter tipo da coluna 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter data de UNIX para DATA\n",
    "df_tratado['time'] = pd.to_datetime(df_tratado['time'], unit='s')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisando coluna 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Title  Price\n",
      "2999990  The Idea of History    NaN\n",
      "2999994  The Idea of History    NaN\n",
      "2999996  The Idea of History    NaN\n",
      "2999997  The Idea of History    NaN\n",
      "2999998  The Idea of History    NaN\n",
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "# Filtrando as linhas que correspondem ao título\n",
    "filtro = df_tratado['Title'] == 'The Idea of History'\n",
    "df_idea = df_tratado.loc[filtro, ['Title', 'Price']]\n",
    "\n",
    "print(df_idea.head(10))\n",
    "print(df_idea['Price'].unique())\n",
    "\n",
    "\n",
    "# Mantive o valores NaN, pois no momento, não irei avaliar os preços e, são muitas livros sem preço (mais de 2 milhões de registros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificar e tratar valores nulos em 'summary' e 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393 valores nulos em summary\n",
      "1 valores nulos em text\n"
     ]
    }
   ],
   "source": [
    "# CONTAGEM DOS VALORES NULOS EM 'summary' e 'text'\n",
    "print(f'{df_tratado[\"summary\"].isnull().sum()} valores nulos em summary')\n",
    "print(f'{df_tratado[\"text\"].isnull().sum()} valores nulos em text')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenchendo com string vazia os valores nulos\n",
    "df_tratado['summary'] = df_tratado['summary'].fillna('')\n",
    "df_tratado['text'] = df_tratado['text'].fillna('')\n",
    "\n",
    "# Pensando na análise de sentimento, como são poucos registros, vou manter os valores nulos, gerando valores neutros na análise de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificar usuários duplicados para o mesmo livro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas duplicadas: 71758\n",
      "             Id                             Title  Price         User_id  \\\n",
      "162  0517150328   History of Magic and the Occult    NaN   AMKC1EJBUXDS2   \n",
      "164  0517150328   History of Magic and the Occult    NaN   AMKC1EJBUXDS2   \n",
      "198  B0007DVHU2            Treat yourself to life    NaN  A1RJD10TTI568L   \n",
      "201  B0007DVHU2            Treat yourself to life    NaN  A1RJD10TTI568L   \n",
      "656  B0000630MU      HTML: The Complete Reference    NaN  A332U346E9T5PU   \n",
      "681  B0000630MU      HTML: The Complete Reference    NaN  A332U346E9T5PU   \n",
      "724  050552421X  The Scarletti Curse (Candleglow)    NaN  A2A9BTNYLA9EA0   \n",
      "726  050552421X  The Scarletti Curse (Candleglow)    NaN  A1PURG5ASALH79   \n",
      "727  050552421X  The Scarletti Curse (Candleglow)    NaN  A1PURG5ASALH79   \n",
      "776  050552421X  The Scarletti Curse (Candleglow)    NaN  A14MF63X40QDT2   \n",
      "\n",
      "                             profileName  score       time  \\\n",
      "162                            Anita Fix    5.0 2001-05-06   \n",
      "164                            Anita Fix    5.0 2001-05-06   \n",
      "198                  Pieter Uys \"Toypom\"    5.0 2000-11-12   \n",
      "201                  Pieter Uys \"Toypom\"    5.0 2009-04-10   \n",
      "656  Mr. M. O'Sullivan \"Mr M O'Sullivan\"    4.0 2001-05-31   \n",
      "681  Mr. M. O'Sullivan \"Mr M O'Sullivan\"    5.0 2001-05-09   \n",
      "724                    R. Peters \"Sapph\"    5.0 2001-03-14   \n",
      "726                          Kelly Owens    4.0 2001-03-10   \n",
      "727                          Kelly Owens    4.0 2001-03-10   \n",
      "776                            Johnna S.    3.0 2001-12-31   \n",
      "\n",
      "                                               summary  \\\n",
      "162  a bibliophiliac wedding of the SURREALIST &amp...   \n",
      "164  a bibliophiliac wedding of the SURREALIST &amp...   \n",
      "198  CLEAR AND INSPIRING EXPLANATION OF SPIRITUAL T...   \n",
      "201                           Harnessing thought-power   \n",
      "656                     Not as good as the 2nd Edition   \n",
      "681               The only HTML book you'll ever need.   \n",
      "724                                       Wonderful!!!   \n",
      "726                      a good start for a new series   \n",
      "727                      a good start for a new series   \n",
      "776                                          It was OK   \n",
      "\n",
      "                                                  text  \n",
      "162  Kurt Seligmann, Surrealist artist par excellen...  \n",
      "164  Kurt Seligmann, Surrealist artist par excellen...  \n",
      "198  Dr Baker explains clearly and engagingly how o...  \n",
      "201  Dr Baker was one of those great 20th century m...  \n",
      "656  This is a great book but I didn't think it was...  \n",
      "681  The first thing you'll notice about this book ...  \n",
      "724  Wonderful book! Very few fans of Feehan's Dark...  \n",
      "726  I first started reading mrs. feehan thru her w...  \n",
      "727  I first started reading mrs. feehan thru her w...  \n",
      "776  This book was a bit different for me perhaps b...  \n"
     ]
    }
   ],
   "source": [
    "# Verificar duplicatas nas colunas 'Id', 'User_id' e 'text'\n",
    "duplicatas = df_tratado.duplicated(subset=['Id', 'User_id'], keep=False)\n",
    "\n",
    "# Contar quantas linhas são consideradas duplicadas\n",
    "quantidade_duplicatas = duplicatas.sum()\n",
    "print(f\"Total de linhas duplicadas: {quantidade_duplicatas}\")\n",
    "\n",
    "# Exibir algumas linhas duplicadas\n",
    "df_duplicadas = df_tratado[duplicatas].head(10)\n",
    "print(df_duplicadas.head(10))\n",
    "\n",
    "# NÃO ADICIONEI O PROFILE NAME, POIS UM USUÁRIO PODE MUDAR O NOME E COMENTAR A MESMA COISA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Id                                              Title  Price  \\\n",
      "75747  0786280670  Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...    NaN   \n",
      "75745  0786280670  Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...    NaN   \n",
      "75746  0786280670  Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...    NaN   \n",
      "\n",
      "              User_id                  profileName  score                time  \\\n",
      "75747   AWF1MPR7NZX07                         Mary    2.0 1969-12-31 23:59:59   \n",
      "75745  A3LL5TMGX00LA1         Virginia Teacher Mom    2.0 1969-12-31 23:59:59   \n",
      "75746  A2ZE8PHSFIQBLQ  Sarah Beagle \"Sarah Beagle\"    1.0 1969-12-31 23:59:59   \n",
      "\n",
      "                                                 summary  \\\n",
      "75747  Disappointing...read My Life in France by Juli...   \n",
      "75745                    For once, the movie was better.   \n",
      "75746                                 Dazed and Confused   \n",
      "\n",
      "                                                    text  \n",
      "75747  I eagerly snatched this book up when I saw it ...  \n",
      "75745  I purchased this book after seeing, and truly ...  \n",
      "75746  I had such high hopes for this book and I was ...  \n"
     ]
    }
   ],
   "source": [
    "# Primeiro, ordene o DataFrame pela coluna 'time'\n",
    "df_tratado = df_tratado.sort_values('time')\n",
    "\n",
    "# Em seguida, remova os duplicados considerando as colunas que identificam o livro e o usuário.\n",
    "# Aqui, estamos usando 'Id' para identificar o livro e 'User_id' para o usuário.\n",
    "# O parâmetro keep='last' garante que o último comentário (mais recente) seja mantido.\n",
    "df_tratado = df_tratado.drop_duplicates(subset=['Id', 'User_id'], keep='last')\n",
    "\n",
    "# Verificando o resultado\n",
    "#print(df_final.shape)\n",
    "print(df_tratado.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas duplicadas após remoção: 0\n"
     ]
    }
   ],
   "source": [
    "# Depois de remover duplicatas, a contagem deve ser zero para o mesmo critério\n",
    "duplicatas_final = df_tratado.duplicated(subset=['Id', 'User_id'], keep=False)\n",
    "print(\"Total de linhas duplicadas após remoção:\", duplicatas_final.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenação das colunas summary e text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratado.loc[:, 'text_concat'] = df_tratado['summary'] + ' ' + df_tratado['text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATAFRAME TRATADO / LIMPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo com sucesso em: c:\\Users\\Thiago_W\\Desktop\\A3_Case\\case_a3data\\app\\data\\books_rating_tratado.csv\n"
     ]
    }
   ],
   "source": [
    "# Define a raiz do projeto e a pasta de dados, conforme sua estrutura\n",
    "PROJECT_ROOT = Path.cwd().parent.parent\n",
    "SAVE_DIR = PROJECT_ROOT / \"case_a3data\" / \"app\" / \"data\"\n",
    "\n",
    "# Cria a pasta, se ela não existir\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define o caminho completo para o arquivo a ser salvo\n",
    "csv_save_path = SAVE_DIR / \"books_rating_tratado.csv\"\n",
    "\n",
    "df_final = df_tratado.copy()  \n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "df_final.to_csv(csv_save_path, index=False)\n",
    "print(f\"Arquivo salvo com sucesso em: {csv_save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMOVI OS COMENTÁRIOS DO MESMO USUÁRIO PARA O LIVRO, MANTENDO APENAS O ÚLTIMO COMENTÁRIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - ANÁLISE DE SENTIMENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AQUI EU POSSO TESTAR DOIS MODELOS: NLTK E bert-base-multilingual-uncased-sentiment (HUGGINFACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>text_concat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0786280670</td>\n",
       "      <td>Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWF1MPR7NZX07</td>\n",
       "      <td>Mary</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>Disappointing...read My Life in France by Juli...</td>\n",
       "      <td>I eagerly snatched this book up when I saw it ...</td>\n",
       "      <td>Disappointing...read My Life in France by Juli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0786280670</td>\n",
       "      <td>Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3LL5TMGX00LA1</td>\n",
       "      <td>Virginia Teacher Mom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>For once, the movie was better.</td>\n",
       "      <td>I purchased this book after seeing, and truly ...</td>\n",
       "      <td>For once, the movie was better. I purchased th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0786280670</td>\n",
       "      <td>Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2ZE8PHSFIQBLQ</td>\n",
       "      <td>Sarah Beagle \"Sarah Beagle\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>Dazed and Confused</td>\n",
       "      <td>I had such high hopes for this book and I was ...</td>\n",
       "      <td>Dazed and Confused I had such high hopes for t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                                              Title  Price  \\\n",
       "0  0786280670  Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...    NaN   \n",
       "1  0786280670  Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...    NaN   \n",
       "2  0786280670  Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...    NaN   \n",
       "\n",
       "          User_id                  profileName  score                time  \\\n",
       "0   AWF1MPR7NZX07                         Mary    2.0 1969-12-31 23:59:59   \n",
       "1  A3LL5TMGX00LA1         Virginia Teacher Mom    2.0 1969-12-31 23:59:59   \n",
       "2  A2ZE8PHSFIQBLQ  Sarah Beagle \"Sarah Beagle\"    1.0 1969-12-31 23:59:59   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Disappointing...read My Life in France by Juli...   \n",
       "1                    For once, the movie was better.   \n",
       "2                                 Dazed and Confused   \n",
       "\n",
       "                                                text  \\\n",
       "0  I eagerly snatched this book up when I saw it ...   \n",
       "1  I purchased this book after seeing, and truly ...   \n",
       "2  I had such high hopes for this book and I was ...   \n",
       "\n",
       "                                         text_concat  \n",
       "0  Disappointing...read My Life in France by Juli...  \n",
       "1  For once, the movie was better. I purchased th...  \n",
       "2  Dazed and Confused I had such high hopes for t...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste = df_final[:1001].copy()\n",
    "df_teste.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "## Precisamos do léxico VADER\n",
    "#nltk.download('vader_lexicon')\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         text_concat  \\\n",
      "0  Disappointing...read My Life in France by Juli...   \n",
      "1  For once, the movie was better. I purchased th...   \n",
      "2  Dazed and Confused I had such high hopes for t...   \n",
      "3  Glad I found this Silver Pennies has made terr...   \n",
      "4  An incomparable children's classic This book o...   \n",
      "5  My favorite book of poetry from childhood My m...   \n",
      "6  A joyful find! This book was given to me when ...   \n",
      "7  What an Incredible Find A dear old friend gave...   \n",
      "8  Found again... This book was given to me over ...   \n",
      "9  Unequalled Collection of Children's Poetry for...   \n",
      "\n",
      "                                    sentiment_scores  compound sentiment_label  \n",
      "0  {'neg': 0.012, 'neu': 0.818, 'pos': 0.169, 'co...    0.9891        positive  \n",
      "1  {'neg': 0.045, 'neu': 0.736, 'pos': 0.219, 'co...    0.9822        positive  \n",
      "2  {'neg': 0.058, 'neu': 0.837, 'pos': 0.105, 'co...    0.8482        positive  \n",
      "3  {'neg': 0.0, 'neu': 0.773, 'pos': 0.227, 'comp...    0.9169        positive  \n",
      "4  {'neg': 0.0, 'neu': 0.701, 'pos': 0.299, 'comp...    0.9451        positive  \n",
      "5  {'neg': 0.0, 'neu': 0.87, 'pos': 0.13, 'compou...    0.8519        positive  \n",
      "6  {'neg': 0.0, 'neu': 0.805, 'pos': 0.195, 'comp...    0.9200        positive  \n",
      "7  {'neg': 0.021, 'neu': 0.808, 'pos': 0.171, 'co...    0.9873        positive  \n",
      "8  {'neg': 0.042, 'neu': 0.824, 'pos': 0.134, 'co...    0.8636        positive  \n",
      "9  {'neg': 0.0, 'neu': 0.838, 'pos': 0.162, 'comp...    0.9263        positive  \n"
     ]
    }
   ],
   "source": [
    "def analisar_sentimento(texto):\n",
    "    # Gera um dicionário com scores\n",
    "    # {'neg': 0.0, 'neu': 0.4, 'pos': 0.6, 'compound': 0.6696}\n",
    "    return sia.polarity_scores(texto)\n",
    "\n",
    "df_teste['sentiment_scores'] = df_teste['text_concat'].apply(analisar_sentimento)\n",
    "\n",
    "df_teste['compound'] = df_teste['sentiment_scores'].apply(lambda d: d['compound'])\n",
    "\n",
    "def classificar_sentimento(score):\n",
    "    if score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df_teste['sentiment_label'] = df_teste['compound'].apply(classificar_sentimento)\n",
    "\n",
    "# Visualizar o resultado\n",
    "print(df_teste[['text_concat', 'sentiment_scores', 'compound', 'sentiment_label']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>text_concat</th>\n",
       "      <th>sentiment_scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0786280670</td>\n",
       "      <td>Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWF1MPR7NZX07</td>\n",
       "      <td>Mary</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>Disappointing...read My Life in France by Juli...</td>\n",
       "      <td>I eagerly snatched this book up when I saw it ...</td>\n",
       "      <td>Disappointing...read My Life in France by Juli...</td>\n",
       "      <td>{'neg': 0.012, 'neu': 0.818, 'pos': 0.169, 'co...</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0786280670</td>\n",
       "      <td>Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3LL5TMGX00LA1</td>\n",
       "      <td>Virginia Teacher Mom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>For once, the movie was better.</td>\n",
       "      <td>I purchased this book after seeing, and truly ...</td>\n",
       "      <td>For once, the movie was better. I purchased th...</td>\n",
       "      <td>{'neg': 0.045, 'neu': 0.736, 'pos': 0.219, 'co...</td>\n",
       "      <td>0.9822</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0786280670</td>\n",
       "      <td>Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2ZE8PHSFIQBLQ</td>\n",
       "      <td>Sarah Beagle \"Sarah Beagle\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>Dazed and Confused</td>\n",
       "      <td>I had such high hopes for this book and I was ...</td>\n",
       "      <td>Dazed and Confused I had such high hopes for t...</td>\n",
       "      <td>{'neg': 0.058, 'neu': 0.837, 'pos': 0.105, 'co...</td>\n",
       "      <td>0.8482</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000G167FA</td>\n",
       "      <td>Silver Pennies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A21KZ6WAO2P1P1</td>\n",
       "      <td>MossMonster</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>Glad I found this</td>\n",
       "      <td>Silver Pennies has made terrific bedtime and q...</td>\n",
       "      <td>Glad I found this Silver Pennies has made terr...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.773, 'pos': 0.227, 'comp...</td>\n",
       "      <td>0.9169</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000G167FA</td>\n",
       "      <td>Silver Pennies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAFZZHA2I598B</td>\n",
       "      <td>Byron C. Benson</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>An incomparable children's classic</td>\n",
       "      <td>This book of children's poems has been enjoyed...</td>\n",
       "      <td>An incomparable children's classic This book o...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.701, 'pos': 0.299, 'comp...</td>\n",
       "      <td>0.9451</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                                              Title  Price  \\\n",
       "0  0786280670  Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...    NaN   \n",
       "1  0786280670  Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...    NaN   \n",
       "2  0786280670  Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...    NaN   \n",
       "3  B000G167FA                                     Silver Pennies    NaN   \n",
       "4  B000G167FA                                     Silver Pennies    NaN   \n",
       "\n",
       "          User_id                  profileName  score                time  \\\n",
       "0   AWF1MPR7NZX07                         Mary    2.0 1969-12-31 23:59:59   \n",
       "1  A3LL5TMGX00LA1         Virginia Teacher Mom    2.0 1969-12-31 23:59:59   \n",
       "2  A2ZE8PHSFIQBLQ  Sarah Beagle \"Sarah Beagle\"    1.0 1969-12-31 23:59:59   \n",
       "3  A21KZ6WAO2P1P1                  MossMonster    5.0 1969-12-31 23:59:59   \n",
       "4   AAFZZHA2I598B              Byron C. Benson    5.0 1969-12-31 23:59:59   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Disappointing...read My Life in France by Juli...   \n",
       "1                    For once, the movie was better.   \n",
       "2                                 Dazed and Confused   \n",
       "3                                  Glad I found this   \n",
       "4                 An incomparable children's classic   \n",
       "\n",
       "                                                text  \\\n",
       "0  I eagerly snatched this book up when I saw it ...   \n",
       "1  I purchased this book after seeing, and truly ...   \n",
       "2  I had such high hopes for this book and I was ...   \n",
       "3  Silver Pennies has made terrific bedtime and q...   \n",
       "4  This book of children's poems has been enjoyed...   \n",
       "\n",
       "                                         text_concat  \\\n",
       "0  Disappointing...read My Life in France by Juli...   \n",
       "1  For once, the movie was better. I purchased th...   \n",
       "2  Dazed and Confused I had such high hopes for t...   \n",
       "3  Glad I found this Silver Pennies has made terr...   \n",
       "4  An incomparable children's classic This book o...   \n",
       "\n",
       "                                    sentiment_scores  compound sentiment_label  \n",
       "0  {'neg': 0.012, 'neu': 0.818, 'pos': 0.169, 'co...    0.9891        positive  \n",
       "1  {'neg': 0.045, 'neu': 0.736, 'pos': 0.219, 'co...    0.9822        positive  \n",
       "2  {'neg': 0.058, 'neu': 0.837, 'pos': 0.105, 'co...    0.8482        positive  \n",
       "3  {'neg': 0.0, 'neu': 0.773, 'pos': 0.227, 'comp...    0.9169        positive  \n",
       "4  {'neg': 0.0, 'neu': 0.701, 'pos': 0.299, 'comp...    0.9451        positive  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Índice 4:\n",
      "\n",
      "Summary:\n",
      "An incomparable children's classic\n",
      "\n",
      "Text:\n",
      "This book of children's poems has been enjoyed by three generations in our family. It captures the imagination of young children and makes a wonderful bedtime reading. I credit this book for giving me an early and continuing love of poetry.\n",
      "\n",
      "sentiment_scores:\n",
      "{'neg': 0.0, 'neu': 0.701, 'pos': 0.299, 'compound': 0.9451}\n",
      "\n",
      "compound:\n",
      "0.9451\n",
      "\n",
      "sentiment_label:\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "# printando o valor de summary e text\n",
    "\n",
    "# Escolha o índice que deseja visualizar (por exemplo, índice 0)\n",
    "indice = 4\n",
    "\n",
    "print(f\"\\nÍndice {indice}:\")\n",
    "print(f\"\\nSummary:\\n{df_teste.loc[indice, 'summary']}\")\n",
    "print(f\"\\nText:\\n{df_teste.loc[indice, 'text']}\")\n",
    "print(f\"\\nsentiment_scores:\\n{df_teste.loc[indice, 'sentiment_scores']}\")\n",
    "print(f\"\\ncompound:\\n{df_teste.loc[indice, 'compound']}\")\n",
    "print(f\"\\nsentiment_label:\\n{df_teste.loc[indice, 'sentiment_label']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bert-base-multilingual-uncased-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            text_concat  bert_sentiment\n",
      "0     Disappointing...read My Life in France by Juli...               2\n",
      "1     For once, the movie was better. I purchased th...               3\n",
      "2     Dazed and Confused I had such high hopes for t...               2\n",
      "3     Glad I found this Silver Pennies has made terr...               5\n",
      "4     An incomparable children's classic This book o...               5\n",
      "...                                                 ...             ...\n",
      "996   Ghost In The Shell is a very cool book ! I'am ...               5\n",
      "997   This story has haunted me for over 25 years I ...               5\n",
      "998   The Best Book Ever Written About a Womens' Bas...               5\n",
      "999   well written and thurough coverage of Os/2 War...               5\n",
      "1000  The Best Book Ever Written About a Womens' Bas...               5\n",
      "\n",
      "[1001 rows x 2 columns]\n",
      "Tempo de execução: 104.26567840576172 segundos\n"
     ]
    }
   ],
   "source": [
    "# TESTE PARA AVALIAR EM QUANTO TEMPO A ANÁLISE DE SENTIMENTO É FEITA\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from time import time\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def sentiment_transformers(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    # Esse modelo retorna 5 classes (1 a 5 estrelas).\n",
    "    # Podemos converter para algo entre -1 e +1, ou simplesmente pegar a classe argmax\n",
    "    star_rating = torch.argmax(probs, dim=1).item() + 1\n",
    "    return star_rating\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_final_teste = df_final[0:1001].copy()\n",
    "\n",
    "\n",
    "start_time = time()\n",
    "df_final_teste[\"bert_sentiment\"] = df_final_teste[\"text_concat\"].apply(sentiment_transformers)\n",
    "print(df_final_teste[[\"text_concat\", \"bert_sentiment\"]])\n",
    "end_time = time()\n",
    "print(f\"Tempo de execução: {end_time - start_time} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>User_id</th>\n",
       "      <th>profileName</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>text_concat</th>\n",
       "      <th>bert_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0786280670</td>\n",
       "      <td>Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWF1MPR7NZX07</td>\n",
       "      <td>Mary</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>Disappointing...read My Life in France by Juli...</td>\n",
       "      <td>I eagerly snatched this book up when I saw it ...</td>\n",
       "      <td>Disappointing...read My Life in France by Juli...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0786280670</td>\n",
       "      <td>Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A3LL5TMGX00LA1</td>\n",
       "      <td>Virginia Teacher Mom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>For once, the movie was better.</td>\n",
       "      <td>I purchased this book after seeing, and truly ...</td>\n",
       "      <td>For once, the movie was better. I purchased th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0786280670</td>\n",
       "      <td>Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A2ZE8PHSFIQBLQ</td>\n",
       "      <td>Sarah Beagle \"Sarah Beagle\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>Dazed and Confused</td>\n",
       "      <td>I had such high hopes for this book and I was ...</td>\n",
       "      <td>Dazed and Confused I had such high hopes for t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000G167FA</td>\n",
       "      <td>Silver Pennies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A21KZ6WAO2P1P1</td>\n",
       "      <td>MossMonster</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>Glad I found this</td>\n",
       "      <td>Silver Pennies has made terrific bedtime and q...</td>\n",
       "      <td>Glad I found this Silver Pennies has made terr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000G167FA</td>\n",
       "      <td>Silver Pennies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAFZZHA2I598B</td>\n",
       "      <td>Byron C. Benson</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>An incomparable children's classic</td>\n",
       "      <td>This book of children's poems has been enjoyed...</td>\n",
       "      <td>An incomparable children's classic This book o...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                                              Title  Price  \\\n",
       "0  0786280670  Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...    NaN   \n",
       "1  0786280670  Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...    NaN   \n",
       "2  0786280670  Julie and Julia: 365 Days, 524 Recipes, 1 Tiny...    NaN   \n",
       "3  B000G167FA                                     Silver Pennies    NaN   \n",
       "4  B000G167FA                                     Silver Pennies    NaN   \n",
       "\n",
       "          User_id                  profileName  score                time  \\\n",
       "0   AWF1MPR7NZX07                         Mary    2.0 1969-12-31 23:59:59   \n",
       "1  A3LL5TMGX00LA1         Virginia Teacher Mom    2.0 1969-12-31 23:59:59   \n",
       "2  A2ZE8PHSFIQBLQ  Sarah Beagle \"Sarah Beagle\"    1.0 1969-12-31 23:59:59   \n",
       "3  A21KZ6WAO2P1P1                  MossMonster    5.0 1969-12-31 23:59:59   \n",
       "4   AAFZZHA2I598B              Byron C. Benson    5.0 1969-12-31 23:59:59   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Disappointing...read My Life in France by Juli...   \n",
       "1                    For once, the movie was better.   \n",
       "2                                 Dazed and Confused   \n",
       "3                                  Glad I found this   \n",
       "4                 An incomparable children's classic   \n",
       "\n",
       "                                                text  \\\n",
       "0  I eagerly snatched this book up when I saw it ...   \n",
       "1  I purchased this book after seeing, and truly ...   \n",
       "2  I had such high hopes for this book and I was ...   \n",
       "3  Silver Pennies has made terrific bedtime and q...   \n",
       "4  This book of children's poems has been enjoyed...   \n",
       "\n",
       "                                         text_concat  bert_sentiment  \n",
       "0  Disappointing...read My Life in France by Juli...               2  \n",
       "1  For once, the movie was better. I purchased th...               3  \n",
       "2  Dazed and Confused I had such high hopes for t...               2  \n",
       "3  Glad I found this Silver Pennies has made terr...               5  \n",
       "4  An incomparable children's classic This book o...               5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_teste.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É notório que o bert performou melhor em relação ao NLTK, para analise de sentimento"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
